{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.5.4/bin/python\n",
    "\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import xarray as xr\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "secprday = 3600*24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select reservoir name\n",
    "reservoir_name = 'Dickson' # possible to replace by: Dickson, Bhumiboi, Waterton, Glen_canyon, Palisades, Trinity, Semione, Sirikit\n",
    "reservoir_name = \"Bhumiboi\"\n",
    "reservoir_name = \"Sirikit\"\n",
    "reservoir_name = 'Waterton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Yassin et al 2019\n",
    "metadata = pd.read_csv('observations/reservoirs_metadata.csv')\n",
    "metadata.index = metadata['name']\n",
    "\n",
    "# get the information\n",
    "purpose = metadata.loc[reservoir_name].purpose\n",
    "max_storage = metadata.loc[reservoir_name].capacity_mcm*10**6\n",
    "\n",
    "\n",
    "# load observations\n",
    "fn = 'observations/res_info_out_'+reservoir_name+'.csv'\n",
    "df = pd.read_csv(fn)\n",
    "df.index = pd.to_datetime(df.timed)\n",
    "df['demand'] = 0 # there are currently no demand observations. Paste calculated demand in here\n",
    "\n",
    "time_unit_nc = \"days since \"+str(pd.to_datetime(df.timed.iloc[0]))\n",
    "print(time_unit_nc)\n",
    "\n",
    "outflow_obs = df['outflow']\n",
    "storage_obs = df['stoobs']; \n",
    "storage_inital = storage_obs[0]; print(storage_inital)\n",
    "inflow = df['inflow']\n",
    "\n",
    "\n",
    "# average inflow (Hanasaki uses naturalised inflow)\n",
    "# here taken as mean over whole observational period\n",
    "mean_inflow = inflow.mean() # (m³/s)\n",
    "\n",
    "mean_inflow_monthly = inflow.groupby([inflow.index.month]).mean() # to adjust for seasonal cycle (m³/s)\n",
    "print(mean_inflow_monthly)\n",
    "\n",
    "# \n",
    "demand_irrig_monthly = np.zeros(12) # [m³/s] \n",
    "\n",
    "if reservoir_name == \"Bhumiboi\": demand_irrig_monthly = np.array([0,150,200,250,200,75,50,50,20,0,30,0])\n",
    "if reservoir_name == \"Sirikit\" : demand_irrig_monthly = np.array([0,50,100,200,100,50,20,50,10,10,0,0])\n",
    "if reservoir_name == \"Waterton\": demand_irrig_monthly = np.array([0,0,5,30,50,50,30,20,5,0,0,0]) # estimated demand (to test demand > inflow * erf)\n",
    "\n",
    "\n",
    "# interpolate estimated monthly demands to average day-of-year values and (demand is zero if non-irrigation reservoir)\n",
    "interp = interp1d(np.linspace(0,11, num=12), demand_irrig_monthly, kind='cubic')\n",
    "demand_irrig_doy = interp(np.linspace(0,11, num=366))\n",
    "\n",
    "# assign daily demand based on corresponding day of year of mean year\n",
    "for d in range(1,367):\n",
    "    df.loc[df.index.dayofyear == d, 'demand'] = demand_irrig_doy[d-1]\n",
    "demand = df.demand\n",
    "    \n",
    "# total annual inflow\n",
    "mean_inflow_yearly = mean_inflow_monthly.mean() # m³/s\n",
    " \n",
    "c = max_storage/(mean_inflow_yearly * secprday * 365) #[m³/yr] # if c>0.5 : large reservoir, if c < 0.5: \"whitin-a-year\" reservoir, if c = 0, reservoir is \"run-of-the-river\"\n",
    "\n",
    "print('reservoir = '+reservoir_name)\n",
    "print(\"purpose = \"+purpose)\n",
    "print(\"c = %.2f\" %c)\n",
    "print(\"mean annual inflow = %.0f m³/s\" %mean_inflow_yearly)\n",
    "print(\"maximum storage = %.0f m³\" %max_storage)\n",
    "print(\"initial storage = %.0f m³\" %storage_inital)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the date frame and create the network topology\n",
    "Ntopo = pd.read_csv('look_up/NetTopo.csv')\n",
    "Ntopo_flags = pd.read_csv('look_up/NetTopo_flags.csv')\n",
    "\n",
    "\n",
    "Ntopo.name.iloc[1] =  reservoir_name\n",
    "Ntopo.H06_Smax     =  max_storage\n",
    "Ntopo.H06_S_ini    =  storage_inital\n",
    "Ntopo.name.iloc[1] =  reservoir_name\n",
    "Ntopo.H06_E_rel_ini=  storage_inital/(max_storage*Ntopo.H06_alpha.iloc[1])\n",
    "Ntopo.H06_I_Jan    =  mean_inflow_monthly.iloc[0]\n",
    "Ntopo.H06_I_Feb    =  mean_inflow_monthly.iloc[1]\n",
    "Ntopo.H06_I_Mar    =  mean_inflow_monthly.iloc[2]\n",
    "Ntopo.H06_I_Apr    =  mean_inflow_monthly.iloc[3]\n",
    "Ntopo.H06_I_May    =  mean_inflow_monthly.iloc[4]\n",
    "Ntopo.H06_I_Jun    =  mean_inflow_monthly.iloc[5]\n",
    "Ntopo.H06_I_Jul    =  mean_inflow_monthly.iloc[6]\n",
    "Ntopo.H06_I_Aug    =  mean_inflow_monthly.iloc[7]\n",
    "Ntopo.H06_I_Sep    =  mean_inflow_monthly.iloc[8]\n",
    "Ntopo.H06_I_Oct    =  mean_inflow_monthly.iloc[9]\n",
    "Ntopo.H06_I_Nov    =  mean_inflow_monthly.iloc[10]\n",
    "Ntopo.H06_I_Dec    =  mean_inflow_monthly.iloc[11]\n",
    "Ntopo.H06_D_Jan    =  demand_irrig_monthly[0]\n",
    "Ntopo.H06_D_Feb    =  demand_irrig_monthly[1]\n",
    "Ntopo.H06_D_Mar    =  demand_irrig_monthly[2]\n",
    "Ntopo.H06_D_Apr    =  demand_irrig_monthly[3]\n",
    "Ntopo.H06_D_May    =  demand_irrig_monthly[4]\n",
    "Ntopo.H06_D_Jun    =  demand_irrig_monthly[5]\n",
    "Ntopo.H06_D_Jul    =  demand_irrig_monthly[6]\n",
    "Ntopo.H06_D_Aug    =  demand_irrig_monthly[7]\n",
    "Ntopo.H06_D_Sep    =  demand_irrig_monthly[8]\n",
    "Ntopo.H06_D_Oct    =  demand_irrig_monthly[9]\n",
    "Ntopo.H06_D_Nov    =  demand_irrig_monthly[10]\n",
    "Ntopo.H06_D_Dec    =  demand_irrig_monthly[11]\n",
    "\n",
    "if purpose == \"irrigation\":\n",
    "    Ntopo.purpose.iloc[1] = 1\n",
    "else:\n",
    "    Ntopo.purpose.iloc[1] = 0\n",
    "\n",
    "Ntopo.to_csv('network_topology/NetTopo_'+reservoir_name+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network topology file with parameters \n",
    "\n",
    "def nc_creation(Ntopo, Ntopo_flags, reservoir_name):\n",
    "    \n",
    "    # remove existing files\n",
    "    if os.path.isfile('./network_topology/network_topology_'+reservoir_name+'.nc'):\n",
    "        os.remove('./network_topology/network_topology_'+reservoir_name+'.nc')\n",
    "\n",
    "    # open the nc file to write\n",
    "    ncid = nc4.Dataset('./network_topology/network_topology_'+reservoir_name+'.nc', \"w\", format=\"NETCDF4\")\n",
    "\n",
    "    # the dimension of the nc file variables is equal to the row of the shapefile\n",
    "    dimid_N = ncid.createDimension('n',Ntopo.shape[0])\n",
    "    dimid_Nchar = ncid.createDimension('nchar',4)\n",
    "\n",
    "    # going through the field one by one and saving them in nc varibales with long name, units and variable type (int, etc)\n",
    "    for column in list(Ntopo_flags.columns):\n",
    "        \n",
    "        print(column, Ntopo_flags[column].iloc[0], Ntopo_flags[column].iloc[1], Ntopo_flags[column].iloc[2])\n",
    "        \n",
    "        # define the variable\n",
    "        varid = ncid.createVariable(column, Ntopo_flags[column].iloc[0],('n',),\\\n",
    "                                    zlib=True,fill_value=Ntopo_flags[column].iloc[2]) #assuming all the fields are floats\n",
    "        # Attributes\n",
    "        varid.long_name      = column\n",
    "        varid.unit           = Ntopo_flags[column].iloc[1]\n",
    "\n",
    "        # Write data\n",
    "        varid[:] = Ntopo[column]\n",
    "    \n",
    "    \n",
    "    # define the variable PFAF\n",
    "    varid = ncid.createVariable('PFAF','S1',('n','nchar',)) #assuming all the fields are floats\n",
    "    # Attributes\n",
    "    varid.long_name      = 'PFAF Order'\n",
    "    varid.unit           = '-'\n",
    "    # preparing the data\n",
    "    data = np.full(Ntopo.shape[0], 'test', 'S4')\n",
    "    data = nc4.stringtochar(data)\n",
    "    varid[:,:]=data\n",
    "\n",
    "    ncid.Conventions = 'CF-1.6'\n",
    "    ncid.License     = 'The data were written by Shervan Gharari. They are under GPL.'\n",
    "    ncid.history     = 'Created ' + time.ctime(time.time())\n",
    "    ncid.source      = 'Written by test script of utilities (https://github.com/ShervanGharari/utility-codes).'\n",
    "    ncid.close()\n",
    "\n",
    "\n",
    "# \n",
    "nc_creation(Ntopo, Ntopo_flags, reservoir_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect created network topology file \n",
    "ds_nettopo = xr.open_dataset('./network_topology/network_topology_'+reservoir_name+'.nc')\n",
    "ds_nettopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the input file for mizuRoute for a network topology of size 3\n",
    "\n",
    "n_dim_length = 3\n",
    "n_dim_time   = len(inflow)\n",
    "\n",
    "print(n_dim_time, n_dim_length)\n",
    "\n",
    "time_data = np.arange(n_dim_time)\n",
    "\n",
    "\n",
    "# save inflow values as runoff\n",
    "values_runoff = np.zeros((n_dim_time, n_dim_length))\n",
    "values_runoff[:,0] = inflow\n",
    "\n",
    "# save demand values (for reservoir ID)\n",
    "values_demand = np.zeros((n_dim_time, n_dim_length))\n",
    "values_demand[:,1] = demand\n",
    "\n",
    "\n",
    "\n",
    "temp = pd.read_csv('network_topology/NetTopo_'+reservoir_name+'.csv')\n",
    "basin_area = temp.basin_area.iloc[1]\n",
    "\n",
    "\n",
    "if os.path.isfile('./network_topology/input_'+reservoir_name+'.nc'):\n",
    "    os.remove('./network_topology/input_'+reservoir_name+'.nc')\n",
    "\n",
    "with nc4.Dataset('./network_topology/input_'+reservoir_name+'.nc', \"w\", format=\"NETCDF4\") as ncid:\n",
    "\n",
    "    dimid_N = ncid.createDimension('n', n_dim_length)  # only write one variable\n",
    "    dimid_T = ncid.createDimension('time', n_dim_time)\n",
    "\n",
    "    # Variables\n",
    "    time_varid = ncid.createVariable('time', 'i4', ('time', ))\n",
    "    # Attributes\n",
    "    time_varid.long_name = 'time'\n",
    "    time_varid.units = time_unit_nc  # e.g. 'days since 1900-01-01 00:00'\n",
    "    time_varid.calendar = 'gregorian'\n",
    "    time_varid.standard_name = 'time'\n",
    "    time_varid.axis = 'T'\n",
    "    # Write data\n",
    "    time_varid[:] = time_data\n",
    "\n",
    "    # Variables\n",
    "    ID_varid = ncid.createVariable('ID', 'int', ('n', ))\n",
    "    # Attributes\n",
    "    ID_varid.long_name = 'ID'\n",
    "    ID_varid.units = '1'\n",
    "    # Write data\n",
    "    ID_varid[:] = np.array([1,2,3])\n",
    "\n",
    "    # Variable\n",
    "    # data_varid = ncid.createVariable(variable_name, 'f8', ('n','time', ), fill_value=-9999)\n",
    "    data_varid = ncid.createVariable('runoff', 'f8', ('time','n', ), fill_value=-9999)\n",
    "    # Attributes\n",
    "    data_varid.long_name = 'runoff'\n",
    "    data_varid.units = 'mm day**-1'\n",
    "    # Write data\n",
    "    data_varid[:]   = values_runoff * secprday/ basin_area * 1000\n",
    "    \n",
    "    # Variable\n",
    "    # data_varid = ncid.createVariable(variable_name, 'f8', ('n','time', ), fill_value=-9999)\n",
    "    data_varid = ncid.createVariable('evapo', 'f8', ('time','n', ), fill_value=-9999)\n",
    "    # Attributes\n",
    "    data_varid.long_name = 'evaporation'\n",
    "    data_varid.units = 'mm day**-1'\n",
    "    # Write data\n",
    "    data_varid[:] = 0\n",
    "    \n",
    "    # Variable\n",
    "    # data_varid = ncid.createVariable(variable_name, 'f8', ('n','time', ), fill_value=-9999)\n",
    "    data_varid = ncid.createVariable('precip', 'f8', ('time','n', ), fill_value=-9999)\n",
    "    # Attributes\n",
    "    data_varid.long_name = 'precipitation'\n",
    "    data_varid.units = 'mm day**-1'\n",
    "    # Write data\n",
    "    data_varid[:] = 0\n",
    "\n",
    "    # Variable\n",
    "    # data_varid = ncid.createVariable(variable_name, 'f8', ('n','time', ), fill_value=-9999)\n",
    "    data_varid = ncid.createVariable('demand', 'f8', ('time','n', ), fill_value=-9999)\n",
    "    # Attributes\n",
    "    data_varid.long_name = 'water demand'\n",
    "    data_varid.units = 'm**3'\n",
    "    # Write data\n",
    "    data_varid[:] = values_demand\n",
    "    \n",
    "    ##\n",
    "    ncid.Conventions = 'CF-1.6'\n",
    "    ncid.License = 'The data were written by Shervan Gharari. Under Apache2.'\n",
    "    ncid.history = 'Created ' + time.ctime(time.time())\n",
    "    ncid.source = 'Written by script from library of Shervan Gharari (https://github.com/ShervanGharari/candex).'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('./network_topology/input_'+reservoir_name+'.nc')\n",
    "ds = xr.open_dataset('./network_topology/network_topology_'+reservoir_name+'.nc')\n",
    "print(ds.lake_model)\n",
    "\n",
    "print(ds.H06_E_rel_ini)\n",
    "ds.runoff[:,0].plot(label='runoff')\n",
    "print(np.array(ds.runoff[:]))\n",
    "\n",
    "ds.demand[:,1].plot(label='demand')\n",
    "plt.legend()\n",
    "print(np.array(ds.demand[:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
